# Vanguard's Company Project

### The Team: Houleye Anne, Ma√Ølys Jaffret

## Project overview 

This project is an experiment conducted by Vanguard's Customer Experience team, with the primary objective of determining whether a new digital user interface (UI) improves the user experience. The experiment was designed with two groups: a Test group, which was exposed to the new UI, and a Control group, which continued using the existing interface.

## Objective

The main question this study aims to answer is : Did the new UI design lead to a higher completion rate among users?

## Project structure

This project involves multiple datasets related to client profiles, digital interactions, and participation in an A/B test. Below is a detailed structure of the datasets used and created throughout the experiment:

### 1. Datasets Used

- DF1: Clients Profile, contains customer information, including demographics and basic profile data.
- DF2: Digital Footprints, includes data on clients online interactions. DF2 was generated by concatenating two different datasets that capture client interactions online.
- DF3: Experiment Roster, holds information about clients who participated in the A/B test, including the group they were assigned to (Test or Control).

### 2. Datasets Created

- df_client_info : created by merging DF1 (client profile data) with the experiment information.
- client_last_start : generated by filtering interactions from DF2. It only retains steps that occurred after the last "start" interaction for each client_id.
- df_total_info : a comprehensive dataset combining all relevant information.

### 3. Final Datasets Created Based on the 'Variation' Column

- df_test : clients who were part of the Test group and interacted with the new digital interface.
- df_control : clients in the Control group who interacted with the original digital interface.
- df_no_participation : clients who did not participate in the A/B test and were excluded from the analysis.

These datasets serve as the foundation for analyzing the impact of the new UI design on client behavior, focusing on the completion rate for both Test and Control groups.

## Tools and Technologies used

### Python: The primary programming language for data cleaning and analysis.

### Pandas & NumPy: For data manipulation and numerical analysis.

- import pandas as pd
- import matplotlib.pyplot as plt
- import seaborn as sns
- import numpy as np

### Sats: for statistic analysis

- import statsmodels.stats.power as smp

- import scipy.stats as st
- import scipy.stats as 
- from scipy.stats import ttest_ind
  
### Matplotlib & Seaborn: Utilized for generating visualizations.

### Jupyter Notebook and Google Colab: Served as the interactive environment for code execution and data exploration.
Complete and clean notebook(s) containing the code, analysis, and visualizations Python files
Jupyter notebook containing the report in full with visualizations

### Tableau: Served to create dashboards

## Findings and Conclusion

### 1- Findings

Based on the analysis of the A/B testd ata, several key insight were identified by KPIs:
- Completion rate improvment for the Test group
- Error rete higher for the Test group

Based on the analysis of the A/B testd ata, several key insight were identified by hypothesis testting:
- Differenc in the completion rate statistically significant (p_value = 0.0)
- Completion rate with a cost-effectivess threshold satiscally significant (p_value = 0.0). Completion rate of the Test group is at least 5% higher then the Control group.
- Error rate analysis : the error group has a significantly greater error rate than the Control group (p_value = 0.0)

### 2- Conclusion

A well-rounded user experience must harmonize both efficiency and accuracy; thus, Vanguard should reassess the design to ensure it meets user needs without increasing errors.
How Vanguard can optimize their  design without compromising user accuracy?

The results indicate that while the Test group shows a notable improvement in completion rates, this improvement comes alongside a worrying rise in error rates. 
This suggests that the current design may prioritize speed at the expense of accuracy, which can adversely affect user satisfaction and overall effectiveness.
Therefore, it's crucial to analyze the design implications and user interactions more thoroughly.

## Deliverables

- One notebook with all the code
- One file in py.files for the functions
- Tableau file
- A slide deck for the project presentation
- A README with a thorough project documentation







